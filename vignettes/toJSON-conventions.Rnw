%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Encoding Common R Data Structures in JSON}

%shorthands
\newcommand{\JSON}{\texttt{JSON}\xspace}

%meta
\documentclass{article}
\author{Jeroen Ooms}
\title{Encoding Common R Data Structures in JSON}

%some packages
\usepackage{url}
\usepackage{fullpage}
\usepackage{setspace}

%extra line spacing
\usepackage{xspace}
\setstretch{1.2}

%actual doc
\begin{document}

\maketitle

<<echo=FALSE>>=
library(JSONlite)
@

\section{Introduction}

JSON (JavaScript Object Notation) is a lightweight data-interchange format, and one of the most common methods today for exchange of simple data structures in systems and applications. It is easy for humans to read and write, and easy for machines to parse and generate. The \JSON format itself is very simple and completely defined in a single page at \url{http://www.json.org/}. This simplicity allows for directly mapping some universal data structures from any programming language into \JSON strings, and vice versa, which is convenient for developers and has contributed to the popularity of the format. Several R packages including \texttt{RJSONIO}, \texttt{rjson} and \texttt{JSONlite} implement \texttt{toJSON} and \texttt{fromJSON} functions which convert between basic R data structures and \JSON.  However, the intuitive mapping in R is limited to lists and vectors; there is no consensus on how some of the other common classes in R, such as factors, matrices and data frames should be mapped to \JSON. Furthermore, upon closer inspection, even the universal data structures in R actually do not perfectly map to their \JSON counterparts, and leave some ambiguity for edge cases. These problems have resulted in different behavior between the current packages, and can lead to unexpected output for certain special cases, which affects reliability of applications that rely on \JSON to get data in and out of R. This document tries to take away some of the ambiguity by describing the mapping a more formally and explicitly, highlighting problems and propose conventions that can generalize the mapping to cover all common classes and cases in R.

\subsection{Reference implementation: the \texttt{JSONlite} package}

The \texttt{JSONlite} package provides a reference implementation of the conventions listed in this document. \texttt{JSONlite} is a fork of the \texttt{RJSONIO} package by Duncan Temple Lang, which again builds on \texttt{libjson} \texttt{C++} library. The \texttt{JSONlite} package uses the parser code from \texttt{RJSONIO}, but the R code has been rewritten from scratch. Both packages implement similar \texttt{toJSON} and \texttt{fromJSON} functions, but their output can be quite different. Finally, the \texttt{JSONlite} package contains a large set of unit tests to validate that R objects are correctly converted to \JSON and vice versa. Any other implementation of the conventions listed in this document can be validated by performing the same unit tests.

<<eval=FALSE>>=
library(testthat)
test_package("JSONlite")
@

\noindent Note that even though \texttt{JSON} allows for inserting arbitrary white space and indentation, the unit tests assume that all white space is trimmed.

\subsection{Class-based versus type-based encoding}

The \texttt{JSONlite} package actually implements two methods for translating between R objects and \JSON. This document focuses on the \texttt{toJSON} and \texttt{fromJSON} functions which use R's class-based S3 method system. For all of the common classes in R, the \texttt{JSONlite} package implements a \texttt{toJSON} method according to the conventions outlined in this document. Users in R can easily extend this system by implementing additional \texttt{toJSON} methods for other classes. However this also means that classes that do not have the \texttt{toJSON} method defined are not supported. Furthermore, the implementation of a specific \texttt{toJSON} method determines which data and metadata in the objects of this class gets encoded in its \JSON representation, and how. In this respect, \texttt{toJSON} is similar to e.g. the \texttt{print} function, which also provides a certain \emph{representation} of an object based on its class and optionally some print parameters. This representation does not necessarily contain all information stored in the object. As a result, there is no one-to-one correspondence between R objects and \JSON strings. I.e. calling \texttt{fromJSON(toJSON(object))} might return an object which only contains the data that was encoded by the \texttt{toJSON} method for this particular class of object, and is not identical to the original object. 

The alternative to the S3 method system is to use type-based encoding, which \texttt{JSONlite} implements in the functions \texttt{serializeJSON} and \texttt{unserializeJSON}. All data structures in R get stored in memory using one of the internal \texttt{SEXP} storage types, and \texttt{serializeJSON} defines an encoding schema which captures the type, value, and attributes for each storage type. The result is \JSON output which closely resembles the internal structure of the underlying C data types, and which can be perfectly restored to the original R object using \texttt{unserializeJSON}. This method is relatively straightforward to implement, however the disadvantage is that the resulting \JSON structure can be very verbose, hard to interpret and cumbersome to generate in the context of another language or system. For most applications this is actually impractical. Usually, we can make data in R objects more accessible to third parties by defining sensible \JSON representation based on the class of an object, rather than its internal storage type. In this document we will not treat \texttt{serializeJSON} in any further detail, and limit ourselves to the class based \texttt{toJSON} and \texttt{fromJSON}. However the reader that is interested in JSON based serialization of R objects is encouraged to have a look at the manual pages.

\subsection{Scope and Limitations}

Before continuing, it is important to be aware of the limitations of representing R data structures in \JSON. First of all, there are the general limitations to types of objects that can be serialized. Temporary in-memory properties such as connections, file descriptors and (recursive) memory references are always difficult if not impossible to store in a sensible way, regardless of the language or serialization method. This document mostly focuses on R classes that hold  data that can be exchanged with other languages, e.g. vectors, lists, dates, matrices, data frames, etc. We are not overly interested in language level constructs such as expressions, functions, promises, which hold little meaning outside the context of R. Then there are limitations in the format itself. \JSON is a human readable, text-based format which does not support binary data, and numbers are stored in their decimal representation. This leads to loss of precision for real numbers, depending on how many digits the user decides to print. Finally, as mentioned earlier, the class based S3 method system allows for concise and practical encoding of the various data structures, but makes that \texttt{fromJSON} is not a perfect inverse function of \texttt{toJSON}, as is the case for e.g. \texttt{serialializeJSON} and \texttt{unserializeJSON}. For example, the \JSON representation of an empty vector, empty list or empty data frame are all the same: \texttt{"[ ]"}. In the design of the functions we target consistent behavior, and try to adhere to the principle of being strict on output and tolerant on input. 

\section{Converting R objects to \JSON}
 
This section lists options and examples of representing the common R classes in \JSON, i.e. the \texttt{toJSON} function in \texttt{JSONlite}. As explained before, we rely on the class based S3 method system in R; hence objects get encoded according to their \texttt{class} value. If an object has multiple \texttt{class} values, R will use the first occurring class which has a \texttt{toJSON} method implemented. If none of the classes of an object has a \texttt{toJSON} method, R will raise an error.

\subsection{Atomic Vectors}

The most basic data type in R is the atomic vector. The atomic vector holds an ordered set of homogeneous values of type \texttt{"logical"} (booleans), \texttt{integer}, \texttt{numeric} (doubles), \texttt{character} (strings), or \texttt{"raw"} (bytes). Because R is fully vectorized, there is no user level notion of a primitive: any scalar value is considered a vector of length 1. Atomic vectors are encoded using a \JSON array:

<<>>=
x <- c(1, 2, pi)
cat(toJSON(x))
@

\noindent The \JSON array is the most natural way of encoding an R vector, however note that the \JSON array is actually heterogeneous and conceptually closer to the \texttt{list} type in R. However \JSON does not distinguish between homogeneous and heterogeneous sets. 

\subsubsection{Missing Values}

A typical domain specific problem when working with statistical data is presented by missing data: a concept foreign to many other languages. Besides regular values, vector types \texttt{logical}, \texttt{integer}, \texttt{character} and \texttt{double} can hold \texttt{NA} as a value. Vectors of type \texttt{double} define three additional types of non finite values: \texttt{NaN}, \texttt{Inf} and \texttt{-Inf}. \JSON does not natively support any of these types; therefore such values values need to be encoded in some other way. There are two obvious approaches. The first one is to use the  \JSON \texttt{null} type. For example:

<<>>=
x <- c(TRUE, FALSE, NA)
cat(toJSON(x))
@

\noindent The other option is to encode missing values as strings by wrapping them in double quotes:

<<>>=
x <- c(1,2,NA,NaN,Inf,10)
cat(toJSON(x))
@

\noindent Both methods have a limitation: the problem with the \texttt{null} type is that there is no way to distinguish between different types of missing data, which is a problem for numeric vectors. The values \texttt{Inf}, \texttt{-Inf}, \texttt{NA} and \texttt{NaN} have a very different meanings, and these should not get lost in the encoding. The problem with encoding missing values as strings is that this method can not be used for character vectors, because the consumer won't be able to distinguish the actual string "NA" and the missing value NA. This would create a likely source of bugs, where clients mistakenly interpret \texttt{"NA"} as an actual value, which is a common problem with text-based formats such as CSV. For this reason, \texttt{JSONlite} uses the following defaults:

\begin{itemize}
 \item Missing values in non-numeric vectors (\texttt{logical}, \texttt{character}) are encoded as \texttt{null}.
 \item Missing values in numeric vectors (\texttt{double}, \texttt{integer}, \texttt{complex}) are encoded as strings.
\end{itemize}

\noindent Some examples:

<<>>=
cat(toJSON(c(TRUE, NA, NA, FALSE)))
cat(toJSON(c("FOO", "BAR", NA, "NA")))
cat(toJSON(c(3.14, NA, NaN, 21, Inf, -Inf)))
cat(toJSON(c(3.14, NA, NaN, 21, Inf, -Inf), NA_as_string=FALSE))
@

\subsubsection{Special vector types: dates, times, factor, complex}

Besides missing values, \JSON also lacks native support for some of the basic vector types in R that frequently appear in data sets. These include vectors of class \texttt{Date}, \texttt{POSIXt} (timestamps), \texttt{factors} and \texttt{complex} vectors. By default, the \texttt{JSONlite} package coerces these types to strings (using \texttt{as.character}):

<<>>=
cat(toJSON(Sys.time() + 1:3))
cat(toJSON(as.Date(Sys.time()) + 1:3))
cat(toJSON(factor(c("foo", "bar", "foo"))))
cat(toJSON(complex(real=runif(3), imaginary=rnorm(3))))
@

\noindent When parsing such \JSON strings, these values will appear as character vectors. In order to obtain the original types, the user needs to manually coerce them back to the desired type using e.g. \texttt{as.POSIXct}, \texttt{as.Date}, \texttt{as.factor} or \texttt{as.complex}. In this respect, \JSON is subject to the same limitations as text based formats such as CSV. 

\subsubsection{Special cases: vectors of length 0 or 1}

Two special cases deserve special attention: vectors of length 0 and vectors of length 1. In \texttt{JSONlite} these are encoded respectively as an empty array, and an array of length 1:

<<>>=
#vectors of length 0 and 1
cat(toJSON(vector()))
cat(toJSON(pi))

#vectors of length 0 and 1 in a named list
cat(toJSON(list(foo=vector())))
cat(toJSON(list(foo=pi)))

#vectors of length 0 and 1 in an unnamed list
cat(toJSON(list(vector())))
cat(toJSON(list(pi)))
@

\noindent This might seem trivial but these cases result in very different behavior between different \JSON packages, which is probably caused by the fact that R does not distinguish between a scalar and a vector of length 1. For example, in the current implementations, both \texttt{RJSONIO} and \texttt{rjson} encode a vector of length one as a \JSON primitive when it appears within a list: 

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Other packages make different choices:}
\hlkwd{cat}\hlstd{(rjson::}\hlkwd{toJSON}\hlstd{(}\hlkwd{list}\hlstd{(}\hlkwc{n} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{))))}
\end{alltt}
\begin{verbatim}
## {"n":1}
\end{verbatim}
\begin{alltt}
\hlkwd{cat}\hlstd{(rjson::}\hlkwd{toJSON}\hlstd{(}\hlkwd{list}\hlstd{(}\hlkwc{n} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{2}\hlstd{))))}
\end{alltt}
\begin{verbatim}
## {"n":[1,2]}
\end{verbatim}
\end{kframe}
\end{knitrout}

\noindent When encoding a single data set this might seem harmless, but in the context of dynamic data this inconsistency is almost guaranteed to cause bugs. For example, imagine an R web service which lets the user fit a linear model and sends back the fitted parameter estimates. In this application, the R server returns the vector with coefficients encoded as a \JSON array. The client code then parses the \JSON, and then iterates over the array of coefficients to display them in a GUI. All goes well, until the user decides to fit a model with only one predictor. If the \JSON encoder returns a primitive value where the client is assuming an array, the application will likely break. Any consumer or client would need to be aware of the special case where the vector becomes a primitive, and explicitly take this exception into account when processing the result. Failure to do so might result in client code might proceed as usual and call an iterator or loop method on a primitive value, resulting in the obvious errors. For this reason \texttt{JSONlite} uses consistent encoding schemes which do not depend on variable object properties such as its length. Hence, a vector is always encoded as an array, even when it is of length 0 or 1.

\subsection{Matrices}

Arguably one of the strongest sides of R is its ability to interface libraries for basic linear algebra subroutines (BLAS) such as LAPACK, OpenBLAS, etc. These libraries provide well tuned, high performance implementations of important linear algebra operations to calculate anything from inner products and eigen values to singular value decompositions. These are in turn the building blocks of many higher level statistical methods such as linear regression or principal component analysis. Linear algebra methods operate on \emph{matrices}, making the matrix one of the most central data classes in R. Conceptually, a matrix consists of a 2 dimensional structure of homogeneous values. It is indexed using 2 numbers (or vectors), representing the row and column number of the matrix respectively. 

<<>>=
x <- matrix(1:12, nrow=3, ncol=4)
print(x)
x[2,4]
@

\noindent Even though the matrix is a 2 dimensional structure, it is stored in memory by R as a single atomic vector with an attribute called \texttt{"dim"} defining the dimensions of the matrix. The product of the dimensions is equal to the length of the vector. 

<<>>=
attributes(volcano)
length(volcano)
@

\noindent Even though the matrix is stored as a single vector, it the way it is printed, indexed and treated otherwise makes it conceptually closer to a set of equal-length homogeneous vectors. For this reason, \texttt{JSONlite} encodes matrices as an array of sub arrays:

<<>>=
x <- matrix(1:12, nrow=3, ncol=4)
cat(toJSON(x))
@

\noindent We hope that this represention will be the most intuitive to interpret, even within languages that do not have a native notion of a matrix. When the JSON string is properly indented (recall that whitespace and linebreaks are optional in JSON), it looks very similar to the way R prints matrices:

\begin{verbatim}
[ [ 1, 4, 7, 10 ], 
  [ 2, 5, 8, 11 ], 
  [ 3, 6, 9, 12 ] ]
\end{verbatim}

\noindent Because the matrix is implemented in R as an atomic vector, it automatically inherits the conventions mentioned earlier with respect to edge cases and missing values:

<<>>=
x <- matrix(c(1,2,4,NA), nrow=2)
cat(toJSON(x))
cat(toJSON(x, , NA_as_string=FALSE))
@


\subsubsection{Matrix row and column names}

Besides the \texttt{"dim"} attribute, matrices in R can have another attribute: \texttt{"dimnames"}. This attribute holds names for the rows and columns in the matrix. However, this information is not included in the default \JSON encoding for matrices for several reasons. First of all, for objects of class matrix the dimnames attribute is optional and often either row names or columes or both are \texttt{NULL}. This makes it difficult to define a practical encoding that covers all cases with and without row and/or column names. Secondly, the names in matrices are mostly there for annotation only; they are not actually used in calculations. For example, the linear algebra operations mentioned before completely ignore them, and do not include any names in their output, so when using these functions there is little purpose of setting them in the first place. For data sets with records consisting of a set of named columns (fields), R has more natural and flexible class: the dataframe. The \texttt{toJSON} method for this dataframes is described below and is much suitable when we want to refer to rows or fields by a particular name. Any matrix can easy be converted to a dataframe using the \texttt{as.data.frame} function.


\subsection{Lists}

The \texttt{list} is the most general purpose data structure in R. It holds an ordered set of elements, including other lists, each of arbitrary type and size. For the purpose of \JSON encoding, two types of lists are distinguished: named lists and unnamed lists. A list is considered a named list if it has an attribute called \texttt{"names"}. In practice, a named list is any list for which we can access an element by its name, whereas elements of an unnamed lists can only be accessed using their index number:

<<>>=
mylist1 <- list("foo" = 123, "bar"= 456)
print(mylist1$bar)
mylist2 <- list(123, 456)
print(mylist2[[2]])
@

\subsubsection{Unnamed lists}

Just like vectors, an unnamed list is encoded using a \JSON array:

<<>>=
cat(toJSON(list(c(1,2), "test")))
cat(toJSON(list(c(1,2), list(c(1,2)))))
@

\noindent Note that even though both vectors and lists are encoded using \JSON arrays, they can be distinguished by looking at their contents: an R vector results in a \JSON array which contains only primitives, whereas a list results in a \JSON array which contains only objects and arrays. This allows the \JSON parser to reconstruct the original type from encoded vectors and arrays:

<<>>=
x <- list(c(1,2,NA), "test", FALSE, list(foo="bar"))
identical(fromJSON(toJSON(x)), x)
@

\noindent The only exception is the empty list and empty vector, which are both encoded as \texttt{[ ]} and therefore indistinguishable, but this is rarely a problem in practice. 

\subsubsection{Named lists}

A named list in R gets encoded as a \JSON \emph{object}:

<<>>=
cat(toJSON(list(foo=c(1,2), bar="test")))
@

\noindent Because a list can contain other lists, this works recursively:

<<tidy=FALSE>>=
cat(toJSON(list(foo=list(bar=list(baz=pi)))))
@

\noindent Named lists map almost perfectly to \JSON objects with one exception: list elements can have empty names:

<<>>=
x <- list(foo=123, "test", TRUE)
attr(x, "names")
x$foo
x[[2]]
@

\noindent In a \JSON object, each element in an object must have a valid name. To ensure this property, \texttt{JSONlite} uses the same solution as the \texttt{print} method, which is to fall back on indices for elements that do not have a proper name:

<<>>=
x <- list(foo=123, "test", TRUE)
print(x)
cat(toJSON(x))
@


\subsection{Data frame}






\section{Converting \JSON to R objects}

Guidelines:

 - try to recover original object
 - at least as.foo(x) should give very similar object.
 - smart is optional ;)


\end{document}